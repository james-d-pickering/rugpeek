{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae215b3-58c4-4ac9-ac31-5f749a3d0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rugpeek_funcs as rp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lmfit as lf\n",
    "import matplotlib as mpl\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec39f2c-c47d-4017-861d-d93c4118bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./example_data/Ferric-Mb_80uM_409nm_SHG_TA_2_matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d790ab4-3a4a-4d45-9a49-729820f1ef28",
   "metadata": {},
   "source": [
    "Now we are going to load this data file and create an object (called a `Rug` here for historical/joke reasons). This object contains all of the data in the file and also contains methods (things that work *on* the data). This paradigm is called **object oriented programming** - the idea is that most analysis methods only make sense in the context of the data actually existing - so we associate the analysis methods explicitly with the data.\n",
    "\n",
    "In Python, what this means is we create a **class** of **objects**. The **object** has associated **attributes** (like, bits of data stored as part of the object), and **methods** (functions that work on the bits of data). There's a file in the folder `/useful_bits/` which contains a jupyter notebook introducing these ideas in a more simple way than directly through this program, which I made for a previous summer student - have a look at it.\n",
    "\n",
    "The definition of the `Rug` class is made in the file `rugpeek_funcs.py`- have a look at it, as you'll be working with this later, but don't panic if it all looks insanely complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63a2d7-d046-4238-b65d-32c32ed45388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JDP create an instance of the Rug class\n",
    "data = rp.Rug(data_file, \".dat\")\n",
    "\n",
    "#JDP look at what kind of object this is:\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b2d8c-f28a-41da-8e11-5ab0a0846ffd",
   "metadata": {},
   "source": [
    "Clearly it's a `Rug` type object. You can see the attributes this object has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c784b-3091-4013-af3b-b1b824741dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b34a92-36aa-4e5d-95ee-40ecd355fc53",
   "metadata": {},
   "source": [
    "This looks like a lot of stuff, but it's just four attributes that jupyter prints out in full. There's the time and wavelength axis of the associated spectrum, then the matrix of absorbance changes, and finally the filename. We can access an individual attribute like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52534306-641e-4303-a799-e244d55bc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc443679-7103-4581-b61a-3c79e5f8c46d",
   "metadata": {},
   "source": [
    "There are also methods associated with this data object. We can see these (and the attributes) as below. The methods that start with a double underscore are inbuilt methods/attributes that Python internally keeps track of - the double underscore is just a convention. The methods we've added are the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5c701-b295-4911-bb01-8f4247d4b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63fb36-df2f-41ef-92b1-9314f00525a3",
   "metadata": {},
   "source": [
    "We can try to use one of these methods: `peek`. This method displays the data in the Rug object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702661b0-e668-4f42-bc5a-7ed6697bdd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JDP note that to use a method we put closing brackets () at the end of the method, whereas for an attribute we left them off.\n",
    "data.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ad964-b16c-4a74-8912-78f21b00f579",
   "metadata": {},
   "source": [
    "Cool - there's a transient absorption spectrum. Another method we can use is one that lets us slice through at a certain wavelength and get the corresponding time trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1c89b-3c93-4837-a417-e93b9aeb76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JDP slice through at 440nm\n",
    "timeslice = data.get_time_trace(440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcc8bf-ca6e-44fd-a9cd-a003070483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JDP can you write the code to plot this trace against time - with labelled axes, and the time axis on a log scale?\n",
    "plt.figure()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
